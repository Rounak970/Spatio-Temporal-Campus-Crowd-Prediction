# ğŸ“¡ Multimodal Spatio-Temporal Crowd Prediction using 3D-CNN + ConvLSTM + Wi-Fi Fusion

A deep learning model that predicts **crowd count**, **density heatmaps**, and **motion patterns** by combining **video frames** and **synthetic Wi-Fi activity signals**.  
This project demonstrates a multimodal architecture capable of understanding both **spatial** and **temporal** crowd dynamics in smart-campus environments.

---

## ğŸŒŸ Overview

Traditional crowd analysis models rely only on video data.  
This project enhances prediction accuracy by fusing:

- ğŸŸ£ **Visual features** (movement, clusters, density)  
- ğŸ”µ **Wi-Fi activity features** (hotspot usage patterns)

By integrating these complementary signals, the model achieves more robust and context-aware crowd understanding.

---

## ğŸ” Key Objectives

- Predict **crowd count** from video sequences  
- Generate **crowd density heatmaps**  
- Estimate **motion flow maps**  
- Combine **spatio-temporal vision signals** with **Wi-Fi behavioral patterns**  
- Build a real-world applicable **smart-campus crowd monitoring system**

---

## ğŸ§  Model Architecture (Multimodal)

The model follows a multi-branch architecture:

### **1ï¸âƒ£ 3D CNN â€” Spatial Feature Extractor**
Learns visual structure + movement from **10-frame clips**.

### **2ï¸âƒ£ ConvLSTM â€” Temporal Modeling**
Captures temporal transitions, crowd flow, and short-term motion cues.

### **3ï¸âƒ£ Wi-Fi Encoder**
A small fully connected network that processes a **10-dimensional synthetic Wi-Fi signal**

### **4ï¸âƒ£ Fusion Layer**
Merges video features and Wi-Fi embeddings.

### **5ï¸âƒ£ Output Heads**
Produces:
- **Crowd Count** `(1,)`
- **Density Map** `(32 Ã— 32)`
- **Motion Map (2 channels)** `(2 Ã— 16 Ã— 16)`

---

## ğŸ“¥ Dataset Links (PETS 2009)

This project uses the **PETS 2009 benchmark dataset**, widely used for crowd analysis.

### ğŸ”¹ **Training Dataset â€” S1 L1**  
Sparse crowd activity  
Download:  
https://motchallenge.net/data/PETS2009-S1-L1/

### ğŸ”¹ **Testing Dataset â€” S1 L2**  
Moderate-density crowd  
Download:  
https://motchallenge.net/data/PETS2009-S1-L2/

---

## ğŸ“¶ Synthetic Wi-Fi Signals

Since PETS does not include Wi-Fi logs, this project uses **synthetic Wi-Fi activity signals**, generated using:

- Time-synchronized fluctuations  
- Gaussian noise  
- Randomized hotspot activity patterns  

These signals serve as a proxy for real-world router activity and enable multimodal learning.

---

## ğŸ“‚ Project Structure

```
campus_crowd_prediction/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_3dcnn_convlstm_model.pth
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ SpatioTemporal_crowd_detection.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ inference.py
â”‚
â”œâ”€â”€ assets/                # Output visualizations
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸ§ª Model Outputs on Test Data

Below are the multimodal modelâ€™s predictions on unseen PETS S1-L2 sequences.

These results reflect the modelâ€™s understanding of **movement**, **density**, and **crowd magnitude** using fused modalities.

---

## ğŸï¸ Input Frames (10-Frame Clip)

<p align="center">
  <img src="assets/input_frames.jpg" width="700"/>
</p>

---

## ğŸ”¢ Predicted Crowd Count

```
Clip Index: 49
Predicted Count: 10.69
```

---

## ğŸ”¥ Predicted Density Map (32Ã—32)

<p align="center">
  <img src="assets/density_map.jpg" width="350"/>
</p>

---

## ğŸŒ€ Motion Map â€” Channel 1

<p align="center">
  <img src="assets/motion_map_ch1.jpg" width="350"/>
</p>

---

## ğŸŒ€ Motion Map â€” Channel 2

<p align="center">
  <img src="assets/motion_map_ch2.jpg" width="350"/>
</p>

---

## ğŸ“ˆ Validation Metrics

| Metric | Value |
|--------|--------|
| **Count MAE** | 0.092 |
| **Density MSE** | 0.00061 |
| **Motion MSE** | 0.000872 |

The low error values indicate strong generalization on unseen data.

---

## ğŸš€ Tech Stack

- **PyTorch** (3D CNN, ConvLSTM)
- **NumPy**, **OpenCV**, **Matplotlib**
- **Google Colab**
- **Multimodal Fusion Techniques**

---

## ğŸ§¾ Final Notes

This project demonstrates:

âœ” Multimodal feature fusion (Video + Wi-Fi)  
âœ” Spatio-temporal learning using 3D CNN + ConvLSTM  
âœ” Multi-task prediction (Count, Density, Motion)  
âœ” Practical evaluation on PETS 2009 dataset  
âœ” Strong generalization on unseen sequences  


The repository includes:
- Model architecture  
- Training workflow  
- Inference pipeline  
- Visualizations  
- Saved model weights  

This framework can be extended to real smart-campus or smart-city monitoring systems.

---

## ğŸ“œ License
This project is released for educational and research purposes.
